# 1. ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° êµ¬í˜„

ğŸ“¢ ì„¤ëª…

* ì†ê¸€ì”¨ ìˆ«ìì´ë¯¸ì§€(MNIST ë°ì´í„°ì…‹)ë¥¼ ì´ìš©í•˜ì—¬ ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ë¥¼ êµ¬í˜„

ğŸ“– ìš”êµ¬ì‚¬í•­

* MNIST ë°ì´í„°ì…‹ì„ ë¡œë“œ

* ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• 

* ê°„ë‹¨í•œ ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì¶•

* ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê³  ì •í™•ë„ë¥¼ í‰ê°€


### MNIST ë°ì´í„°ì…‹ ë¡œë“œ, ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• 

      (x_train, y_train), (x_test, y_test) = mnist.load_data()

* mnist.load_data()ëŠ” ìˆ«ì ì´ë¯¸ì§€ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

* x_train, y_train: í›ˆë ¨ìš© ë°ì´í„° (ì´ë¯¸ì§€ì™€ ì •ë‹µ ìˆ«ì)

* x_test, y_test: í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° (ëª¨ë¸ì´ ì˜ í•™ìŠµí–ˆëŠ”ì§€ í™•ì¸í•  ë•Œ ì‚¬ìš©)

ex) x_train[0]ì€ ìˆ«ì ì´ë¯¸ì§€ í•˜ë‚˜ (ì˜ˆ: 28x28 í¬ê¸°), y_train[0]ì€ ì´ë¯¸ì§€ê°€ ì–´ë–¤ ìˆ«ìì¸ì§€ (ì˜ˆ: 5)


### ê°„ë‹¨í•œ ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì¶•
```python
model = Sequential([
    Dense(128, activation='relu', input_shape=(784,)),
    Dense(10, activation='softmax')
])
```
Sequential 

* ì‹ ê²½ë§ ëª¨ë¸ì„ ìˆœì„œëŒ€ë¡œ ì¸µì„ ìŒ“ì•„ì„œ ë§Œë“ ë‹¤ëŠ” ëœ»

Dense

* 128 -> 128ê°œ ë‰´ëŸ° ì¸µ

* activation = 'relu' -> í™œì„±í™” í•¨ìˆ˜ ReLU ì‚¬ìš©

* input_shape=(784,) -> ì…ë ¥ ë°ì´í„°ëŠ” 784ê°œ ìˆ«ì (28x28 ì´ë¯¸ì§€ í•œì¥ ì„ ëœ»í•¨)

* 10 -> ì¶œë ¥ì´ 10ê°œë¼ëŠ” ëœ» (ìˆ«ì 0~9 ì´ 10ê°œ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜)

* activation = 'softmax' -> í™•ë¥ ì²˜ëŸ¼ ë§Œë“¤ì–´ì„œ ê°€ì¥ ë†’ì€ ê°’ì„ ì •ë‹µìœ¼ë¡œ ì„ íƒ


### ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê³  ì •í™•ë„ë¥¼ í‰ê°€
```python
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5, batch_size=32)

test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}")
```
* loss='sparse_categorical_crossentropy -> ì •ë‹µê³¼ ì˜ˆì¸¡ê°’ì´ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ì§€ ê³„ì‚°í•´ì£¼ëŠ” ë°©ë²•

* metrics = ['accuracy'] -> ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ê¸°ì¤€ì„ ì •í•  ë•Œ ì‚¬ìš© (accuracy - ì •í™•ë„ ì¸¡ì •)

* model.evaluate(x_test, y_test) -> í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë„£ì–´ì„œ ì–¼ë§ˆë‚˜ ì˜ ë§ì¶”ëŠ”ì§€ í‰ê°€


### ì „ì²´ ì½”ë“œ
```python
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt
import matplotlib as mpl

# 1. MNIST ë°ì´í„°ì…‹ ë¡œë“œ
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 2. ë°ì´í„° ì „ì²˜ë¦¬: ì •ê·œí™” ë° í‰íƒ„í™”
x_train = x_train / 255.0
x_test = x_test / 255.0

x_train = x_train.reshape(-1, 28 * 28)
x_test = x_test.reshape(-1, 28 * 28)

# 3. ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì„±
model = Sequential([
    Dense(128, activation='relu', input_shape=(784,)),
    Dense(10, activation='softmax')  # ìˆ«ì 0~9 ë¶„ë¥˜
])

# 4. ëª¨ë¸ ì»´íŒŒì¼
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 5. ëª¨ë¸ í›ˆë ¨ (History ê°ì²´ë¡œ ê²°ê³¼ ì €ì¥)
history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)

# 6. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ í‰ê°€
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}")

# 7. ì„±ëŠ¥ ì‹œê°í™”
plt.figure(figsize=(12, 5))

plt.rcParams['font.family'] = 'Malgun Gothic'
mpl.rcParams['axes.unicode_minus'] = False

# ì •í™•ë„ ì‹œê°í™”
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='í›ˆë ¨ ì •í™•ë„')
plt.plot(history.history['val_accuracy'], label='ê²€ì¦ ì •í™•ë„')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('ì •í™•ë„')
plt.legend()

plt.tight_layout()
plt.show()

```


### ì‹¤í–‰ ê²°ê³¼

![image](https://github.com/user-attachments/assets/ff5c3346-0c51-4992-b96a-e3fa51867e4b)



# 2. CIFAR-10 ë°ì´í„°ì…‹ì„ í™œìš©í•œ CNN ëª¨ë¸ êµ¬ì¶•

ğŸ“¢ ì„¤ëª…

*  CIFAR-10 ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ í•©ì„±ê³± ì‹ ê²½ë§(CNN)ì„ êµ¬ì¶•í•˜ê³ , ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰

ğŸ“– ìš”êµ¬ì‚¬í•­

* CIFAR-10 ë°ì´í„°ì…‹ì„ ë¡œë“œ

* ë°ì´í„°ì „ì²˜ë¦¬(ì •ê·œí™”ë“±)ë¥¼ ìˆ˜í–‰

* CNN ëª¨ë¸ì„ ì„¤ê³„í•˜ê³  í›ˆë ¨

* ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰


### CIFAR-10 ë°ì´í„°ì…‹ì„ ë¡œë“œ
```python
from tensorflow.keras import datasets

(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()
```
* CIFAR-10ì€ 32x32 í¬ê¸°ì˜ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹


### ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰
```python
x_train, x_test = x_train / 255.0, x_test / 255.0
```
* ì´ë¯¸ì§€ í”½ì…€ ê°’ (0~255) -> 0 ~ 1 ì‚¬ì´ ì†Œìˆ˜ë¡œ ë³€ê²½(í•™ìŠµì„ ì‰½ê²Œ í•˜ê¸° ìœ„í•´)


### CNN ëª¨ë¸ì„ ì„¤ê³„í•˜ê³  í›ˆë ¨
```python
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),

    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')  # CIFAR-10ì€ 10ê°œì˜ í´ë˜ìŠ¤
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=10, 
                    validation_data=(x_test, y_test))
```
Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))

* 32 : ì‚¬ì§„ì˜ í¬ê¸°ê°€ 32 x 32 ì´ë¯€ë¡œ 32ê°œì˜ ì»¤ë„ì„ ë§Œë“¬

* (3, 3) : ê° í•„í„°ì˜ í¬ê¸° 3 í”½ì…€ -> ì‘ì€ ë¶€ë¶„ì„ ë³´ë©° íŠ¹ì§•ì„ ì°¾ì•„ëƒ„

* activation = 'relu' : ìŒìˆ˜ëŠ” 0ìœ¼ë¡œ ì–‘ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ í†µê³¼ì‹œí‚´ -> ë³µì¡í•œ íŒ¨í„´ ì˜ ë°°ì›€

* input_shape = (32, 32, 3) : CIFAR-10 í•œ ì´ë¯¸ì§€ì˜ í¬ê¸° (3 -> RGBì˜ë¯¸)

MaxPooling2D((2, 2))

* (2, 2) : 2í”½ì…€ Ã— 2í”½ì…€ -> ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì´ë©´ì„œ ì¤‘ìš”í•œ íŠ¹ì§•ë§Œ ë‚¨ê¹€ + ê³¼ì í•© ë°©ì§€

  
* loss='sparse_categorical_crossentropy': ìˆ«ì(ì •ìˆ˜)ë¡œ ë˜ì–´ ìˆì„ ë•Œ ì“°ëŠ” ë¶„ë¥˜ìš© ì†ì‹¤í•¨ìˆ˜


### ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€, í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰
```python
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f'\n í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}')

predictions = model.predict(x_test)
```

### ì „ì²´ ì½”ë“œ
```python
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np

# 1. CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ
(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()

# 2. ë°ì´í„° ì „ì²˜ë¦¬ - ì •ê·œí™” (0~255 -> 0~1)
x_train, x_test = x_train / 255.0, x_test / 255.0

# 3. CNN ëª¨ë¸ ì„¤ê³„
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),

    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')  # CIFAR-10ì€ 10ê°œì˜ í´ë˜ìŠ¤
])

# 4. ëª¨ë¸ ì»´íŒŒì¼
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 5. ëª¨ë¸ í›ˆë ¨
history = model.fit(x_train, y_train, epochs=10, 
                    validation_data=(x_test, y_test))

# 6. ì„±ëŠ¥ í‰ê°€
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f'\n í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}')

# 7. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì¸¡
predictions = model.predict(x_test)

# 8. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

def plot_image(i, predictions_array, true_label, img):
    true_label, img = int(true_label[i]), img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])

    plt.imshow(img, cmap=plt.cm.binary)

    predicted_label = np.argmax(predictions_array[i])
    color = 'blue' if predicted_label == true_label else 'red'
    plt.xlabel(f"{class_names[predicted_label]} ({100*np.max(predictions_array[i]):.2f}%)\n[ì •ë‹µ: {class_names[true_label]}]",
               color=color)

# ì‹œê°í™”
plt.figure(figsize=(6,3))
plot_image(0, predictions, y_test, x_test)
plt.show()
```

### ê²°ê³¼ í™”ë©´

![image](https://github.com/user-attachments/assets/9366cfba-a81d-4c64-9adf-2904897b9f3f)

